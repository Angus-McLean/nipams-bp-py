{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 202202_SimplestRun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Connect & Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/app\n"
     ]
    }
   ],
   "source": [
    "import os; from importlib import reload;\n",
    "from utils.constants import *\n",
    "%cd {os.environ['PROJECT_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/scipy/io/matlab/_mio.py:226: MatReadWarning: Duplicate variable name \"None\" in stream - replacing previous with new\n",
      "Consider mio5.varmats_from_mat to split file into single variable files\n",
      "  matfile_dict = MR.get_variables(variable_names)\n",
      "/usr/local/lib/python3.8/site-packages/scipy/io/matlab/_mio.py:226: MatReadWarning: Duplicate variable name \"None\" in stream - replacing previous with new\n",
      "Consider mio5.varmats_from_mat to split file into single variable files\n",
      "  matfile_dict = MR.get_variables(variable_names)\n",
      "/usr/local/lib/python3.8/site-packages/scipy/io/matlab/_mio.py:226: MatReadWarning: Duplicate variable name \"None\" in stream - replacing previous with new\n",
      "Consider mio5.varmats_from_mat to split file into single variable files\n",
      "  matfile_dict = MR.get_variables(variable_names)\n",
      "/usr/local/lib/python3.8/site-packages/scipy/io/matlab/_mio.py:226: MatReadWarning: Duplicate variable name \"None\" in stream - replacing previous with new\n",
      "Consider mio5.varmats_from_mat to split file into single variable files\n",
      "  matfile_dict = MR.get_variables(variable_names)\n"
     ]
    }
   ],
   "source": [
    "from data import load_data; reload(load_data)\n",
    "\n",
    "# load_data.fetch_data_from_local(folder='data/raw_mat/', pattern='LLV')\n",
    "dfBpAll, dfImuAll = load_data.load_dataframe_from_mat(folder='data/raw_mat/', pattern='LLV')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Process Signal Data in Heartbeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/src/data/preprocess.py:100: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfBpAll = dfBpAll.append(BpTargets)\n",
      "/app/src/data/preprocess.py:101: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfImuRawAll = dfImuRawAll.append(dfImuSamp)\n",
      "/app/src/data/preprocess.py:100: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfBpAll = dfBpAll.append(BpTargets)\n",
      "/app/src/data/preprocess.py:101: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfImuRawAll = dfImuRawAll.append(dfImuSamp)\n",
      "/app/src/data/preprocess.py:100: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfBpAll = dfBpAll.append(BpTargets)\n",
      "/app/src/data/preprocess.py:101: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfImuRawAll = dfImuRawAll.append(dfImuSamp)\n",
      "/app/src/data/preprocess.py:100: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfBpAll = dfBpAll.append(BpTargets)\n",
      "/app/src/data/preprocess.py:101: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  dfImuRawAll = dfImuRawAll.append(dfImuSamp)\n"
     ]
    }
   ],
   "source": [
    "from utils import constants\n",
    "from data import preprocess\n",
    "\n",
    "dfAll = preprocess.merge_imu_vcg_with_heartbeats(dfBpAll, dfImuAll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Define Data Splits (Patients, Heartbeats, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import experiments\n",
    "\n",
    "dfImu = dfAll[constants.INDICIES + constants.IMU_COLS]\n",
    "dfBp = dfAll[constants.INDICIES + constants.BP_COLS]\n",
    "\n",
    "sampleRandTestInds = experiments.split_by_random(dfImu, dfBp)\n",
    "sampleExpDfs = experiments.get_experiment(sampleRandTestInds[0], dfImu, dfBp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Modeling Pipelines (Baselines & Analytical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import analytical_mvd\n",
    "tsExplodeTransform = preprocess.FunctionTransformer(partial(preprocess.explode_3d, data_cols=['az','ax']))\n",
    "\n",
    "from models import baselines, analytical_mvd\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe_random = Pipeline([('scaler', tsExplodeTransform), ('rand', baselines.RandomRegressor())])\n",
    "pipe_mean = Pipeline([('scaler', tsExplodeTransform), ('rand', baselines.DummyRegressor())])\n",
    "pipe_mvd = Pipeline([('scaler', tsExplodeTransform), ('rand', analytical_mvd.AnalyticalBPEstimator())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Achieved Score (MAE) :  12.019386528349258 Pipeline(steps=[('scaler',\n",
      "                 FunctionTransformer(func=functools.partial(<function explode_3d at 0x7f7410720700>, data_cols=['az', 'ax']))),\n",
      "                ('rand',\n",
      "                 <models.baselines.RandomRegressor object at 0x7f740fdfe0a0>)])\n",
      "Achieved Score (MAE) :  11.035529513367152 Pipeline(steps=[('scaler',\n",
      "                 FunctionTransformer(func=functools.partial(<function explode_3d at 0x7f7410720700>, data_cols=['az', 'ax']))),\n",
      "                ('rand', DummyRegressor())])\n",
      "Fitted Parameters :  {'k1': 10000.0, 'k2': 68.0}\n",
      "Achieved Score (MAE) :  14.008086386091126 Pipeline(steps=[('scaler',\n",
      "                 FunctionTransformer(func=functools.partial(<function explode_3d at 0x7f7410720700>, data_cols=['az', 'ax']))),\n",
      "                ('rand', AnalyticalBPEstimator(k1=10000.0, k2=68.0))])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "for pipe in [pipe_random, pipe_mean, pipe_mvd]:\n",
    "    pipe.fit(sampleExpDfs['train_x'], sampleExpDfs['train_y'].groupby(constants.INDICIES)['dbp'].mean())\n",
    "    score = mean_absolute_error(\n",
    "        pipe.predict(sampleExpDfs['test_x']),\n",
    "        sampleExpDfs['test_y'].groupby(constants.INDICIES)['dbp'].mean()\n",
    "    )\n",
    "    print('Achieved Score (MAE) : ', score, pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted Parameters :  {'k1': 10000.0, 'k2': 68.0}\n",
      "Achieved Score (MAE) :  14.008086386091126\n"
     ]
    }
   ],
   "source": [
    "pipe = pipe_mvd\n",
    "\n",
    "train_y = sampleExpDfs['train_y'].groupby(constants.INDICIES)['dbp'].mean()\n",
    "test_y = sampleExpDfs['test_y'].groupby(constants.INDICIES)['dbp'].mean()\n",
    "\n",
    "pipe.fit(sampleExpDfs['train_x'], train_y)\n",
    "preds = pipe.predict(sampleExpDfs['test_x'])\n",
    "\n",
    "score_mae = mean_absolute_error(preds, test_y)\n",
    "print('Achieved Score (MAE) : ', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
